{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble modelling notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.data_preprocessing.data_loader import load_data, time_split\n",
    "from src.modeling.evaluation import smape, mae\n",
    "from src.modeling.univariate_modeling import (\n",
    "    get_best_cv_model,\n",
    ")\n",
    "from src.data_preprocessing.feature_engineering import preprocessor\n",
    "from config.config_data import (\n",
    "    GROUPING_FUNCS,\n",
    "    GROUPING_NAMES,\n",
    "    GROUPING_VARS,\n",
    "    TIME_VARS,\n",
    "    DROP_VARS,\n",
    ")\n",
    "from sklearn.linear_model import Ridge, Lasso, LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = (\n",
    "    Path(\"..\")\n",
    "    / \"..\"\n",
    "    / \"..\"\n",
    "    / \"hfactory_magic_folders\"\n",
    "    / \"plastic_cost_prediction\"\n",
    "    / \"data\"\n",
    ")\n",
    "MAIN_FILE = \"PA6_cleaned_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(DATA_DIR / MAIN_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best univariate models for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_best_cv_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "split = time_split(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble modelling to predict the best compound price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def univar_preds_per_split(\n",
    "    df: pd.DataFrame,\n",
    "    target: str,\n",
    "    train_idx: np.ndarray[int],\n",
    "    test_idx: np.ndarray[int],\n",
    "    univar_models: dict[str, dict],\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Given a split between train and test, computes a dataframe with the predictions\n",
    "    of the best univar models for each column for the test set.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "      Original dataset for which we want to get the univar model predictions.\n",
    "    target: str\n",
    "      Target variable of the dataset.\n",
    "    train_idx: np.ndarray[int]\n",
    "      Indexes of the elements in the training set.\n",
    "    test_idx: np.ndarray[int]\n",
    "      Indexes of the elements in the test set.\n",
    "    univar_models: dict[str,dict]\n",
    "      Dict of models with evalutaion information for each column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    univar_preds_df: pd.DataFrame\n",
    "      Dataframe with the predictions of the best univar model for each column.\n",
    "    \"\"\"\n",
    "    # get selected models\n",
    "    models_selected = {\n",
    "        k: {v[\"selected\"]: v[v[\"selected\"]]} for k, v in univar_models.items()\n",
    "    }\n",
    "\n",
    "    # predict test values with best model for each column on the train data\n",
    "    best_models = {}\n",
    "    for col, val in models_selected.items():\n",
    "        if col != target:\n",
    "            model_type = list(val.keys())[0]\n",
    "            test = df[col].iloc[test_idx]\n",
    "            train = df[col].iloc[train_idx]\n",
    "\n",
    "            if model_type == \"baseline\":\n",
    "                # define constant value for last point in train data\n",
    "                best_models[col] = list(np.ones(3) * df[col].iloc[-1])\n",
    "\n",
    "            elif model_type == \"ARIMA\":\n",
    "                # fit ARIMA with best order and seasonal order\n",
    "                model = ARIMA(\n",
    "                    train,\n",
    "                    order=val[model_type][\"order\"],\n",
    "                    seasonal_order=val[model_type][\"seasonal_order\"],\n",
    "                )\n",
    "                model_fit = model.fit()\n",
    "                test = df[col].iloc[test_idx]\n",
    "                preds = model_fit.predict(\n",
    "                    start=test.index[0], end=test.index[-1]\n",
    "                )\n",
    "\n",
    "                preds_for_model = [preds[2], preds[5], preds[8]]\n",
    "                best_models[col] = preds_for_model\n",
    "\n",
    "            elif model_type == \"ETS\":\n",
    "                # fit ETS with best trend, season and seasonal periods\n",
    "                model = ExponentialSmoothing(\n",
    "                    train,\n",
    "                    trend=val[model_type][\"trend\"],\n",
    "                    seasonal=val[model_type][\"seasonal\"],\n",
    "                    seasonal_periods=val[model_type][\"seasonal_periods\"],\n",
    "                )\n",
    "                model_fit = model.fit()\n",
    "                preds = model_fit.predict(\n",
    "                    start=test.index[0], end=test.index[-1]\n",
    "                )\n",
    "                preds_for_model = [preds[2], preds[5], preds[8]]\n",
    "\n",
    "                best_models[col] = preds_for_model\n",
    "\n",
    "            elif model_type == \"XGB\":\n",
    "                preds_for_model = []\n",
    "                for horizon in [3, 6, 9]:\n",
    "                    X_train = df.iloc[train_idx]\n",
    "                    X_test = df.iloc[np.append(train_idx, test_idx)]\n",
    "\n",
    "                    # lag horizon+ to create exogenous columns\n",
    "                    for lag in range(horizon, horizon + 12):\n",
    "                        X_train[f\"lag_{lag}\"] = X_train[col].shift(lag)\n",
    "                        X_test[f\"lag_{lag}\"] = X_test[col].shift(lag)\n",
    "\n",
    "                    # get train data\n",
    "                    X_train = X_train.dropna()\n",
    "                    y_train = X_train[col]\n",
    "                    X_train = X_train.drop(columns=col)\n",
    "\n",
    "                    # get test data\n",
    "                    X_test = X_test.dropna()\n",
    "                    X_test = X_test.drop(columns=col)\n",
    "\n",
    "                    # fit model for fold and horizon\n",
    "                    model = XGBRegressor(max_depth=3)\n",
    "                    model.fit(X_train, y_train)\n",
    "                    # get target and prediction for horizon\n",
    "                    preds_for_model.append(model.predict(X_test)[horizon - 1])\n",
    "                best_models[col] = preds_for_model\n",
    "    # creating the dataframe\n",
    "    univar_preds_df = pd.DataFrame.from_dict(best_models)\n",
    "    # adding time as as index of the dataframe\n",
    "    time = [\n",
    "        df.index[test_idx][2],\n",
    "        df.index[test_idx][5],\n",
    "        df.index[test_idx][8],\n",
    "    ]\n",
    "    univar_preds_df[\"time\"] = time\n",
    "    univar_preds_df = univar_preds_df.set_index(\"time\")\n",
    "    return univar_preds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_method_univar_preds(\n",
    "    df: pd.DataFrame,\n",
    "    target: str,\n",
    "    model_list: List[str],\n",
    "    split: List[Tuple[np.ndarray[int], np.ndarray[int]]],\n",
    "    univar_models: dict[str, dict],\n",
    ") -> dict[str, dict]:\n",
    "    \"\"\"Given a list of the best prediction models and the models to test,\n",
    "    returns a dict with the MAE ans SMAPE for the different ensemble models.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df: pd.DataFrame\n",
    "      Dataframe for which we want to make predictions.\n",
    "    target: str\n",
    "      Target variable.\n",
    "    model_list: List[str]\n",
    "      List of ensemble models we want to test.\n",
    "    split: List[Tuple[np.ndarray[int], np.ndarray[int]]]\n",
    "      Different splits used in cross validation.\n",
    "    univar_models: dict[str, dict])\n",
    "      Dict of models with evalutaion information for each column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    results: dict[str, dict]\n",
    "      Dictionary containing the metric scores for each of the ensemble models.\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    ## doing feature engineering\n",
    "    processed_df = preprocessor(\n",
    "        GROUPING_VARS,\n",
    "        GROUPING_NAMES,\n",
    "        GROUPING_FUNCS,\n",
    "        TIME_VARS,\n",
    "        DROP_VARS,\n",
    "        df=df,\n",
    "    )\n",
    "    X = processed_df.drop(target, axis=1)\n",
    "    Y = processed_df[target]\n",
    "    # intializing the results dictionary\n",
    "    results = dict()\n",
    "    # calculating all the metrics for each ensemble model\n",
    "    for mod in model_list:\n",
    "        # initializing the metrics\n",
    "        total_smape = 0\n",
    "        total_mae = 0\n",
    "        preds_3 = []\n",
    "        preds_6 = []\n",
    "        preds_9 = []\n",
    "        target_3 = []\n",
    "        target_6 = []\n",
    "        target_9 = []\n",
    "        preds = []\n",
    "        Smape_per_fold = []\n",
    "        mae_per_fold = []\n",
    "        # calculating smape and mae for each split\n",
    "        for train_idx, test_idx in split:\n",
    "            if mod == \"Ridge\":\n",
    "                model = Ridge()\n",
    "            elif mod == \"Lasso\":\n",
    "                model = Lasso()\n",
    "            elif mod == \"LR\":\n",
    "                model = LinearRegression()\n",
    "            elif mod == \"XGB\":\n",
    "                model = XGBRegressor(max_depth=3)\n",
    "            elif mod == \"RF\":\n",
    "                model = RandomForestRegressor(max_depth=3)\n",
    "            # fittig the model\n",
    "            X_train = X.iloc[train_idx]\n",
    "            Y_train = Y.iloc[train_idx]\n",
    "            Y_test = Y.iloc[test_idx]\n",
    "            model.fit(X_train, Y_train)\n",
    "            # getting predictions for the predicted values.\n",
    "            X_test = univar_preds_per_split(\n",
    "                df, target, train_idx, test_idx, univar_models\n",
    "            )\n",
    "            X_test = preprocessor(\n",
    "                GROUPING_VARS,\n",
    "                GROUPING_NAMES,\n",
    "                GROUPING_FUNCS,\n",
    "                TIME_VARS,\n",
    "                DROP_VARS,\n",
    "                df=X_test,\n",
    "            )\n",
    "            # calculating the different metrics\n",
    "            preds_for_metrics = model.predict(X_test)\n",
    "            Y_for_metrics = np.array([Y_test[2], Y_test[5], Y_test[8]])\n",
    "            sMAPE = smape(Y_for_metrics, preds_for_metrics)\n",
    "            MAE = mae(Y_for_metrics, preds_for_metrics)\n",
    "            for pred in preds_for_metrics:\n",
    "                preds += [pred]\n",
    "            preds_3.append(preds_for_metrics[0])\n",
    "            preds_6.append(preds_for_metrics[1])\n",
    "            preds_9.append(preds_for_metrics[2])\n",
    "            target_3.append(Y_for_metrics[0])\n",
    "            target_6.append(Y_for_metrics[1])\n",
    "            target_9.append(Y_for_metrics[2])\n",
    "            total_smape += sMAPE\n",
    "            Smape_per_fold += [sMAPE]\n",
    "            total_mae += MAE\n",
    "            mae_per_fold += [MAE]\n",
    "        total_smape_3 = smape(np.array(target_3), np.array(preds_3))\n",
    "        total_smape_6 = smape(np.array(target_6), np.array(preds_6))\n",
    "        total_smape_9 = smape(np.array(target_9), np.array(preds_9))\n",
    "        total_mae_3 = mae(np.array(target_3), np.array(preds_3))\n",
    "        total_mae_6 = mae(np.array(target_6), np.array(preds_6))\n",
    "        total_mae_9 = mae(np.array(target_9), np.array(preds_9))\n",
    "        results[mod] = {\n",
    "            \"SMAPE\": total_smape / len(split),\n",
    "            \"MAE\": total_mae / len(split),\n",
    "            \"SMAPE_3\": total_smape_3,\n",
    "            \"MAE_3\": total_mae_3,\n",
    "            \"SMAPE_6\": total_smape_6,\n",
    "            \"MAE_6\": total_mae_6,\n",
    "            \"SMAPE_9\": total_smape_9,\n",
    "            \"MAE_9\": total_mae_9,\n",
    "            \"preds\": preds,\n",
    "            \"smape_per_fold\": Smape_per_fold,\n",
    "            \"mae_per_fold\": mae_per_fold,\n",
    "        }\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = ensemble_method_univar_preds(\n",
    "    df,\n",
    "    \"best_price_compound\",\n",
    "    [\"Ridge\", \"Lasso\", \"LR\", \"RF\", \"XGB\"],\n",
    "    split,\n",
    "    models,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting predictions vs True Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = results[\"XGB\"][\"preds\"]\n",
    "pred_times = []\n",
    "for _, test_idx in split:\n",
    "    for i in range(len(test_idx)):\n",
    "        if i % 3 == 2:\n",
    "            pred_times += [df.index[test_idx[i]]]\n",
    "\n",
    "pred_df = pd.DataFrame(\n",
    "    list(zip(pred_times, preds)), columns=[\"Time\", \"Predictions\"]\n",
    ")\n",
    "pred_df = pred_df.set_index(\"Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df.index, df[\"best_price_compound\"], label=\"Target\", color=\"blue\")\n",
    "plt.scatter(\n",
    "    pred_df.index, pred_df[\"Predictions\"], label=\"Predictions\", color=\"orange\"\n",
    ")\n",
    "plt.title(\"Target vs. Predictions per Fold\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Best Compound Price\")\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
